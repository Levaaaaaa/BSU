{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import enum\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import typing as tp\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics._scorer import _check_multimetric_scoring\n",
    "from sklearn.model_selection._validation import _score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y: np.ndarray) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Computes Gini index for given set of labels\n",
    "    :param y: labels\n",
    "    :return: Gini impurity\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    p = counts / counts.sum()\n",
    "    gini_index = 1 - np.sum(p**2)\n",
    "\n",
    "#    raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8333333333333333)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0, 1, 2, 3, 4, 5])\n",
    "res = gini(y)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "print(np.array(counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_impurity(y_left: np.ndarray, y_right: np.ndarray) -> \\\n",
    "        tp.Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Computes weighted impurity by averaging children impurities\n",
    "    :param y_left: left  partition\n",
    "    :param y_right: right partition\n",
    "    :return: averaged impurity, left child impurity, right child impurity\n",
    "    \"\"\"\n",
    "    weighted_impurity = (y_left.shape[0] * gini(y_left) + y_right.shape[0] * gini(y_right)) / (y_left.shape[0] + y_right.shape[0])\n",
    "    left_impurity = gini(y_left)\n",
    "    right_impurity = gini(y_right)\n",
    "#    raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "    return weighted_impurity, left_impurity, right_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6666666666666666),\n",
       " np.float64(0.6666666666666667),\n",
       " np.float64(0.6666666666666667))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = weighted_impurity(y[:3], y[3:])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(feature_values: np.ndarray, threshold: float) -> tp.Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    splits given 1-d array according to relation to threshold into two subarrays\n",
    "    :param feature_values: feature values extracted from data\n",
    "    :param threshold: value to compare with\n",
    "    :return: two sets of indices\n",
    "    \"\"\"\n",
    "    left_idx = [i for i in range(feature_values.shape[0]) if feature_values[i] <= threshold]\n",
    "    right_idx = [i for i in range(feature_values.shape[0]) if feature_values[i] > threshold]\n",
    "    #raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "    return left_idx, right_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5]\n",
      "[0, 1, 2, 3]\n",
      "[4, 5]\n"
     ]
    }
   ],
   "source": [
    "l, r = create_split(y, 3)\n",
    "print(y)\n",
    "print(l)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _best_split(self, X: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    finds best split\n",
    "    :param X: Data, passed to node\n",
    "    :param y: labels\n",
    "    :return: best feature, best threshold, left child impurity, right child impurity\n",
    "    \"\"\"\n",
    "    lowest_impurity = np.inf\n",
    "    best_feature_id = None\n",
    "    best_threshold = None\n",
    "    lowest_left_child_impurity, lowest_right_child_impurity = None, None\n",
    "    features = self._meta.rng.permutation(X.shape[1])\n",
    "    for feature in features:\n",
    "        current_feature_values = X[:, feature]\n",
    "        thresholds = np.unique(current_feature_values)\n",
    "        for threshold in thresholds:\n",
    "            # find indices for split with current threshold\n",
    "            left_inds, right_inds = create_split(current_feature_values, threshold)\n",
    "            y_left = np.array([y[i] for i in left_inds])\n",
    "            y_right = np.array([y[i] for i in right_inds])\n",
    "            current_weighted_impurity, current_left_impurity, current_right_impurity = weighted_impurity(y_left, y_right)  # calcualte impurity for given indices\n",
    "            #raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "            if current_weighted_impurity < lowest_impurity:\n",
    "                lowest_impurity = current_weighted_impurity\n",
    "                best_feature_id = feature\n",
    "                best_threshold = threshold\n",
    "                lowest_left_child_impurity = current_left_impurity\n",
    "                lowest_right_child_impurity = current_right_impurity\n",
    "\n",
    "    return best_feature_id, best_threshold, lowest_left_child_impurity, lowest_right_child_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeType(enum.Enum):\n",
    "    REGULAR = 1\n",
    "    TERMINAL = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeNode:\n",
    "    \"\"\"\n",
    "    Auxiliary class serving as representation of a decision tree node\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            meta: 'MyDecisionTreeClassifier',\n",
    "            depth,\n",
    "            node_type: NodeType = NodeType.REGULAR,\n",
    "            predicted_class: tp.Optional[tp.Union[int, str]] = None,\n",
    "            left_subtree: tp.Optional['MyDecisionTreeNode'] = None,\n",
    "            right_subtree: tp.Optional['MyDecisionTreeNode'] = None,\n",
    "            feature_id: int = None,\n",
    "            threshold: float = None,\n",
    "            impurity: float = np.inf\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        :param meta: object, holding meta information about tree\n",
    "        :param depth: depth of this node in a tree (is deduced on creation by depth of ancestor)\n",
    "        :param node_type: 'regular' or 'terminal' depending on whether this node is a leaf node\n",
    "        :param predicted_class: class label assigned to a terminal node\n",
    "        :param feature_id: index if feature to split by\n",
    "        :param\n",
    "        \"\"\"\n",
    "        self._node_type = node_type\n",
    "        self._meta = meta\n",
    "        self._depth = depth\n",
    "        self._predicted_class = predicted_class\n",
    "        self._class_proba = None\n",
    "        self._left_subtree = left_subtree\n",
    "        self._right_subtree = right_subtree\n",
    "        self._feature_id = feature_id\n",
    "        self._threshold = threshold\n",
    "        self._impurity = impurity\n",
    "\n",
    "    def _best_split(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        finds best split\n",
    "        :param X: Data, passed to node\n",
    "        :param y: labels\n",
    "        :return: best feature, best threshold, left child impurity, right child impurity\n",
    "        \"\"\"\n",
    "        lowest_impurity = np.inf\n",
    "        best_feature_id = None\n",
    "        best_threshold = None\n",
    "        lowest_left_child_impurity, lowest_right_child_impurity = None, None\n",
    "        features = self._meta.rng.permutation(X.shape[1])\n",
    "        for feature in features:\n",
    "            current_feature_values = X[:, feature]\n",
    "            thresholds = np.unique(current_feature_values)\n",
    "            for threshold in thresholds:\n",
    "                # find indices for split with current threshold\n",
    "                left_inds, right_inds = create_split(current_feature_values, threshold)\n",
    "                y_left = np.array([y[i] for i in left_inds])\n",
    "                y_right = np.array([y[i] for i in right_inds])\n",
    "                current_weighted_impurity, current_left_impurity, current_right_impurity = weighted_impurity(y_left, y_right)  # calcualte impurity for given indices\n",
    "                #raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "                if current_weighted_impurity < lowest_impurity:\n",
    "                    lowest_impurity = current_weighted_impurity\n",
    "                    best_feature_id = feature\n",
    "                    best_threshold = threshold\n",
    "                    lowest_left_child_impurity = current_left_impurity\n",
    "                    lowest_right_child_impurity = current_right_impurity\n",
    "\n",
    "        return best_feature_id, best_threshold, lowest_left_child_impurity, lowest_right_child_impurity\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, all_classes = None):\n",
    "        \"\"\"\n",
    "        recursively fits a node, providing it with predicted class or split condition\n",
    "        :param X: Data\n",
    "        :param y: labels\n",
    "        :return: fitted node\n",
    "        \"\"\"\n",
    "\n",
    "        if all_classes == None:\n",
    "            all_classes = np.unique(y)\n",
    "        #raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        if (\n",
    "                len(set(y)) == 1 \n",
    "                or self._meta.min_samples_split > X.shape[0] \n",
    "                or (self._meta.max_depth is not None and self._depth >= self._meta.max_depth)\n",
    "                 # complete all conditions by which this node should be terminal\n",
    "        ):\n",
    "            self._node_type = NodeType.TERMINAL\n",
    "            general_counts = {c:0 for c in all_classes}\n",
    "            values,counts = np.unique(y, return_counts=True)      \n",
    "            for c, count in zip(values, counts):\n",
    "                general_counts[c] = count / len(y)\n",
    "            self._predicted_class = values[counts.argmax()] # choose most common class\n",
    "    #        proba = [0.0 for i in range(self._meta._n_classes)]\n",
    "    #        for c, count in zip([i for i in range(len(y))],counts):\n",
    "   #             proba[c] = count / len(y)\n",
    "            self._class_proba = list(general_counts.values()) # vector of probabilities of all classes with index from 0 to n_classes-1 (_n_classes from tree class)\n",
    "            return self\n",
    "\n",
    "        self._feature_id, self._threshold, left_imp, right_imp = self._best_split(X, y)\n",
    "        left_idx, right_idx = create_split(X[:, self._feature_id], self._threshold)\n",
    "        self._left_subtree = MyDecisionTreeNode(\n",
    "            meta=self._meta,\n",
    "            depth=self._depth+1,  # adjust depth\n",
    "            impurity=left_imp\n",
    "        ).fit(\n",
    "            np.array([X[i] for i in left_idx]),\n",
    "            np.array([y[i] for i in left_idx]), # choose proper data to fit\n",
    "            all_classes=all_classes\n",
    "        )\n",
    "        self._right_subtree = MyDecisionTreeNode(\n",
    "            meta=self._meta,\n",
    "            depth=self._depth+1,  # adjust depth\n",
    "            impurity=right_imp\n",
    "        ).fit(\n",
    "            np.array([X[i] for i in right_idx]),\n",
    "            np.array([y[i] for i in right_idx]),\n",
    "            all_classes=all_classes\n",
    "             #  choose data to fit\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        Predicts class for a single object\n",
    "        :param x: object of shape (n_features, )\n",
    "        :return: class assigned to object\n",
    "        \"\"\"\n",
    " #       raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        if self._node_type is NodeType.TERMINAL:\n",
    "            return self._predicted_class\n",
    "        if x[self._feature_id] <= self._threshold:\n",
    "            return self._left_subtree.predict(x)\n",
    "            #pass  # look for an answer recursively\n",
    "        else:\n",
    "            return self._right_subtree.predict(x)\n",
    "\n",
    "    def predict_proba(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        Predicts probability for a single object\n",
    "        :param x: object of shape (n_features, )\n",
    "        :return: vector of probabilities assigned to object\n",
    "        \"\"\"\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        if self._node_type is NodeType.TERMINAL:\n",
    "            return self._class_proba\n",
    "        if x[self._feature_id] <= self._threshold:\n",
    "            return self._left_subtree._class_proba  # look for an answer recursively\n",
    "        else:\n",
    "            return self._right_subtree._class_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    \"\"\"\n",
    "    Class analogous to sklearn implementation of decision tree classifier with Gini impurity criterion,\n",
    "    named in a manner avoiding collisions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_depth: tp.Optional[int] = None,\n",
    "            min_samples_split: tp.Optional[int] = 2,\n",
    "            seed: int = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param max_depth: maximal depth of tree, prevents overfitting\n",
    "        :param min_samples_split: minimal amount of samples for node to be a splitter node\n",
    "        :param seed: seed for RNG, enables reproducibility\n",
    "        \"\"\"\n",
    "        self.root = MyDecisionTreeNode(self, 1)\n",
    "        self._is_trained = False\n",
    "        self.max_depth = max_depth or np.inf\n",
    "        self.min_samples_split = min_samples_split or 2\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self._n_classes = 0\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        starts recursive process of node criterion fitting from the root\n",
    "        :param X: Data\n",
    "        :param y: labels\n",
    "        :return: fitted self\n",
    "        \"\"\"\n",
    "        self._n_classes = np.unique(y).shape[0]\n",
    "        self.root.fit(X, y)\n",
    "        self._is_trained = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicts class for a sequence of objects\n",
    "        :param x: Data\n",
    "        :return: classes assigned to each object\n",
    "        \"\"\"\n",
    "        if not self._is_trained:\n",
    "            raise RuntimeError('predict call on untrained model')\n",
    "        else:\n",
    "            #raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "            # predict class for each object\n",
    "            return np.array([self.root.predict(s) for s in X])\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicts class for a sequence of objects\n",
    "        :param x: Data\n",
    "        :return: probabilities of all classes for each object\n",
    "        \"\"\"\n",
    "        if not self._is_trained:\n",
    "            raise RuntimeError('predict call on untrained model')\n",
    "        else:\n",
    "            res = np.array([])\n",
    "            for s in X:\n",
    "                res = np.append(res, self.root.predict_proba(s))\n",
    "            return res\n",
    "#            raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "            # predict class probabilities for each object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyDecisionTreeClassifier at 0x181d7d8fd50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = MyDecisionTreeClassifier()\n",
    "tree.fit(np.empty((1,2)), np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "p = tree.predict_proba(np.empty((1,2)))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Data-diverse ensemble of tree calssifiers\n",
    "    \"\"\"\n",
    "    big_number = 1 << 32\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_estimators: int,\n",
    "            max_depth: tp.Optional[int] = None,\n",
    "            min_samples_split: tp.Optional[int] = 2,\n",
    "            seed: int = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_estimators: number of trees in forest\n",
    "        :param max_depth: maximal depth of tree, prevents overfitting\n",
    "        :param min_samples_split: minimal amount of samples for node to be a splitter node\n",
    "        :param seed: seed for RNG, enables reproducibility\n",
    "        \"\"\"\n",
    "        self._n_classes = 0\n",
    "        self._is_trained = False\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.estimators = [\n",
    "            MyDecisionTreeClassifier(max_depth, min_samples_split, seed=seed) for\n",
    "            seed in self.rng.choice(max(MyRandomForestClassifier.big_number, n_estimators), size=(n_estimators,),\n",
    "                                    replace=False)]\n",
    "\n",
    "    def _bootstrap_sample(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        returns bootstrapped sample from X of equal size\n",
    "        :param X: objects collection to sample from\n",
    "        :param y: corresponding labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        indices = self.rng.integers(0, len(X), size=len(X))  # bootstrap indices with equal probability from X\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        fits each estimator of the ensemble on the bootstrapped data sample\n",
    "        :param X: Data\n",
    "        :param y: labels\n",
    "        :return: fitted self\n",
    "        \"\"\"\n",
    "        self._n_classes = np.unique(y).shape[0]\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        for estimator in self.estimators:\n",
    "            bootstarped_x, bootstraped_y = self._bootstrap_sample(X, y) # fit each estimator on a bootstrapped sample\n",
    "            estimator.fit(bootstarped_x, bootstraped_y)\n",
    "        self._is_trained = True\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        predict probability of each class by averaging over all base estimators\n",
    "        :param X: Data\n",
    "        :return: array of probabilities\n",
    "        \"\"\"\n",
    "        probas = np.zeros((X.shape[0], self._n_classes))\n",
    "        all_probas = np.array([tree.predict_proba(X) for tree in self.estimators])\n",
    "\n",
    "        probas = np.mean(all_probas, axis=0)\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        # get averaged probabilities from each estimator\n",
    "        return probas\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict class for each object\n",
    "        :param X: Data\n",
    "        :return: array of class labels\n",
    "        \"\"\"\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "\n",
    "        return np.argmax(self.predict_proba(X), axis=1) # most probable class for each object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentHandler:\n",
    "    \"\"\"This class perfoms experiments with given model, measures metrics and logs everything for thorough comparison\"\"\"\n",
    "    stacking_prediction_filename = 'cv_stacking_prediction.npy'\n",
    "    test_stacking_prediction_filename = 'test_stacking_prediction.npy'\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            X_train: pd.DataFrame,\n",
    "            y_train: pd.Series,\n",
    "            X_test: pd.DataFrame,\n",
    "            y_test: pd.Series,\n",
    "            cv_iterable: tp.Union[sklearn.model_selection.KFold, tp.Iterable],\n",
    "            logger: Logger,\n",
    "            metrics: tp.Dict[str, tp.Union[tp.Callable, str]],\n",
    "            n_jobs=-1\n",
    "    ):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self._cv_iterable = cv_iterable\n",
    "        self.logger = logger\n",
    "        self._metrics = metrics\n",
    "        self._n_jobs = n_jobs\n",
    "\n",
    "    def score_test(self, estimator, metrics, run, test_data=None):\n",
    "        \"\"\"\n",
    "        Computes scores for test data and logs them to given run\n",
    "        :param estimator: fitted estimator\n",
    "        :param metrics: metrics to compute\n",
    "        :param run: run to log into\n",
    "        :param test_data: optional argument if one wants to pass augmented test dataset\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if test_data is None:\n",
    "            test_data = self.X_test\n",
    "        test_scores = _score(estimator, test_data, self.y_test, metrics)\n",
    "        run.log_values({key + '_test': value for key, value in test_scores.items()})\n",
    "\n",
    "    def score_cv(self, estimator, metrics, run):\n",
    "        \"\"\"\n",
    "        computes scores on cross-validation\n",
    "        :param estimator: estimator to fit\n",
    "        :param metrics: metrics to compute\n",
    "        :param run: run to log to\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        cross_val_results = sklearn.model_selection.cross_val_score(estimator=estimator, X=self.X_train, y=self.y_train, cv=self._cv_iterable, scoring=metrics)  # compute crossval scores (easier done using corresponding sklearn method)\n",
    "        for key, value in cross_val_results.items():\n",
    "            if key.startswith('test_'):\n",
    "                metric_name = key.split('_', maxsplit=1)[1]\n",
    "                mean_score = np.mean(value)\n",
    "                std_score = np.std(value)\n",
    "                run.log_values(\n",
    "                    {\n",
    "                        metric_name + '_mean': mean_score,\n",
    "                        metric_name + '_std': std_score\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def generate_stacking_predictions(self, estimator, run):\n",
    "        \"\"\"\n",
    "        generates predictions over cross-validation folds, then saves them as artifacts\n",
    "        returns fitted estimator for convinience and les train overhead\n",
    "        :param estimator: estimator to use\n",
    "        :param run: run to log to\n",
    "        :return: estimator fitted on train, stacking cross-val predictions, stacking test predictions\n",
    "        \"\"\"\n",
    "#        raise NotImplementedError(\"COMPLETE THIS FUNCTION\")\n",
    "        if hasattr(estimator, \"predict_proba\"):  # choose the most informative method for stacking predictions\n",
    "            method = \"predict_proba\"\n",
    "        elif hasattr(estimator, \"decision_function\"):\n",
    "            method = \"decision_function\"\n",
    "        else:\n",
    "            method = \"predict\"\n",
    "        cross_val_stacking_prediction = sklearn.model_selection.cross_val_predict(estimator=estimator, X=self.X_test, y=self.y_test, cv=self._cv_iterable, method=method)  # generate crossval predictions for stacking using most informative method\n",
    "        run.log_artifact(ExperimentHandler.stacking_prediction_filename,\n",
    "                         lambda file: np.save(file, cross_val_stacking_prediction))\n",
    "        estimator.fit(self.X_train, self.y_train)\n",
    "        test_stacking_prediction = getattr(estimator, method)(self.X_test)\n",
    "        run.log_artifact(ExperimentHandler.test_stacking_prediction_filename,\n",
    "                         lambda file: np.save(file, test_stacking_prediction))\n",
    "        return estimator, cross_val_stacking_prediction, test_stacking_prediction\n",
    "\n",
    "    def get_metrics(self, estimator):\n",
    "        \"\"\"\n",
    "        get callable metrics with estimator validation\n",
    "        (e.g. estimator has predict_proba necessary for likelihood computation, etc)\n",
    "        \"\"\"\n",
    "        return _check_multimetric_scoring(estimator, self._metrics)\n",
    "\n",
    "    def run(self, estimator: sklearn.base.BaseEstimator, name=None):\n",
    "        \"\"\"\n",
    "        perform run for given estimator\n",
    "        :param estimator: estimator to use\n",
    "        :param name: name of run for convinience and consitent logging\n",
    "        :return: leaderboard with conducted run\n",
    "        \"\"\"\n",
    "        metrics = self.get_metrics(estimator)\n",
    "        with self.logger.run(name=name) as run:\n",
    "            # compute predictions over cross-validation\n",
    "            self.score_cv(estimator, metrics, run)\n",
    "            fitted_on_train, _, _ = self.generate_stacking_predictions(estimator, run)\n",
    "            self.score_test(fitted_on_train, metrics, run, test_data=self.X_test)\n",
    "            return self.logger.leaderboard.loc[[run.name]]\n",
    "\n",
    "    def get_stacking_predictions(self, run_names):\n",
    "        \"\"\"\n",
    "        :param run_names: run names for which to extract stacking predictions for averaging and stacking\n",
    "        :return: dataframe with predictions indexed by run names\n",
    "        \"\"\"\n",
    "        train_dataframes = []\n",
    "        test_dataframes = []\n",
    "        for run_name in run_names:\n",
    "            train_filename = self.logger.path / run_name / ExperimentHandler.stacking_prediction_filename\n",
    "            train_dataframes.append(load_predictions_dataframe(filename=train_filename, column_prefix=run_name,\n",
    "                                                               index=self.X_train.index))\n",
    "            test_filename = self.logger.path / run_name / ExperimentHandler.test_stacking_prediction_filename\n",
    "            test_dataframes.append(load_predictions_dataframe(filename=test_filename, column_prefix=run_name,\n",
    "                                                              index=self.X_test.index))\n",
    "\n",
    "        return pd.concat(train_dataframes, axis=1), pd.concat(test_dataframes, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ExperimentHandler.__init__() missing 7 required positional arguments: 'X_train', 'y_train', 'X_test', 'y_test', 'cv_iterable', 'logger', and 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[43mExperimentHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: ExperimentHandler.__init__() missing 7 required positional arguments: 'X_train', 'y_train', 'X_test', 'y_test', 'cv_iterable', 'logger', and 'metrics'"
     ]
    }
   ],
   "source": [
    "handler = ExperimentHandler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
